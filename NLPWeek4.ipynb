{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPWeek4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPkFax9tCskR35PqoyGkaOP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShrimanthAM/NLPClass/blob/master/NLPWeek4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igyeXjPEiF0m"
      },
      "source": [
        "## Exercise 1. Sentiment Analysis\n",
        "This exercise will allow you to use PyTorch. Refer to the DATA 690 Resources.\n",
        "1. Import the required libraries.\n",
        "2. Load the dataset containing a set of 1,000 product reviews from Amazon, which are paired with a label of 0 (for negative reviews) or 1 (for positive reviews). Get the data at https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences.\n",
        "3. Separate the data into two variables: one containing the reviews and the other containing the labels. Remove the punctuation from the reviews.\n",
        "4. Create a variable containing the vocabulary of the entire set of reviews.\n",
        "5. Additionally, create a dictionary that maps each word to an integer, where the words will be the keys and the integers will be the values.\n",
        "6. Encode the reviews data by replacing each word in a review for its paired integer.\n",
        "7. Create a class containing the architecture of the network.\n",
        "8. Make sure that you include an embedding layer. Initialize the model using 64 embedding dimensions and 128 neurons for 3 LSTM layers.\n",
        "9. Define the loss function, an optimization algorithm, and the number of epochs to train for. For example, you can use binary cross-entropy loss as the loss function, the Adam optimizer, and train for 10 epochs.\n",
        "10. Create a for loop that goes through the different epochs and through every single review individually. For each review, perform a prediction, calculate the loss function, and update the parameters of the network. Additionally, calculate the accuracy of the network over that training data.\n",
        "11. Plot the progress of the loss function and accuracy over time.\n",
        "DATA 690 Sentiment Analysis Pytorch LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaT8xPl6iGu5"
      },
      "source": [
        "import pandas as pd "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aIHo6N8iPQu"
      },
      "source": [
        "import torch "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlyfjZAQiQgy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5upda2mMjoc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MilObHfHMmyo"
      },
      "source": [
        "## Q2\n",
        "\n",
        "Perform the following task on the above sentences:\n",
        "1. Replace special characters with empty spaces. You can use regex or any other method\n",
        "2. Remove multiple empty spaces and replace them by a single space\n",
        "3. Remove any single character\n",
        "4. Convert the text to all lower case\n",
        "5. Split the text to individual words\n",
        "6. Remove stopwords\n",
        "7. Tokenize, stem, and lemmatize the text\n",
        "6. What is the overall sentiment and subjectivity of the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVze38YdMoqh"
      },
      "source": [
        "sentence =\"The larger Broncos will be available with 35-inch off-road tires and will be able to drive through water nearly 3 feet, 10 inches deep. It has independent front suspension, unlike its main competitor, the Jeep Wrangler. Independent suspension, used on almost all modern passenger vehicles, generally provides a smoother ride and better on-road handling than a single solid axle. It still has a solid axle in the back though, like most pickup trucks, a design suited to hard use. Like the Wrangler, both the two- and four-door Bronco will have a removable roofs and doors. Buyers will be able to choose either a hard roof that can be removed in sections, a cloth top, or both. Unlike the Wrangler, though, the Bronco's doors will fit inside the vehicle after being removed. The Bronco will be available with a choice of either a 10-speed automatic or seven-speed manual transmission. (The manual transmission will have six gears for ordinary driving, plus a seventh for low speed off-road driving.) It will be powered by either a 270-horsepower 2.3-liter turbocharged 4-cylinder engine or a 310-horsepower 2.7-liter turbocharged V6. While all of the new Bronco SUVs are designed for hard off-road use, the Bronco Sport isn't quite as hard-core in its capabilities. It also has more convenience features than the more truck-like Bronco. While it's based on engineering that's similar to car-like crossover SUVs, Ford says that it's still intended for serious off-road use. Ford engineers boasted of the off-road testing the prototypes have been put through, including driving through deep sand, up steep inclines and crawling across boulder-strewn trails.\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_t73YqzM6sm"
      },
      "source": [
        "import re \n",
        "import nltk "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm7GoRH_NANL"
      },
      "source": [
        "s1=re.sub(r\"[^\\w ]\",\" \", sentence)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd7IjDNS3BvS"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUep4VSK3Ezr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}